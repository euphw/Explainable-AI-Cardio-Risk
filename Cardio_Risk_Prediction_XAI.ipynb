{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# High-risk Project: Explainable AI for Cardiovascular Risk Prediction from Clinical Notes\n",
        "\n",
        "## Project Overview\n",
        "This project is part of a high-risk AI in healthcare assignment. The goal is to predict cardiovascular disease risk from hospital discharge summaries using both traditional NLP (TF-IDF) and advanced contextual embeddings (ClinicalBERT). We also apply SHAP for explainability to identify the most influential features driving the predictions.\n",
        "\n",
        "The workflow includes:\n",
        "1. Data extraction from MIMIC-III via BigQuery.\n",
        "2. Text preprocessing and baseline model training (TF-IDF + Logistic Regression).\n",
        "3. Contextual embeddings using ClinicalBERT, followed by Logistic Regression and XGBoost classifiers.\n",
        "4. Explainability analysis using SHAP to compare feature importance between traditional and embedding-based models.\n",
        "\n",
        "By comparing the performance and interpretability of these methods, we aim to explore whether large language model embeddings can outperform simpler text representations in a real clinical prediction task.\n"
      ],
      "metadata": {
        "id": "eLDtJ8NXRpXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install Dependencies\n",
        "# Install necessary libraries for the project\n",
        "!pip install transformers shap xgboost scikit-learn pandas numpy matplotlib"
      ],
      "metadata": {
        "id": "sbjlOsDqa9cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDOKTb4UBAvz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "BASE = \".\"\n",
        "\n",
        "DIR_DATA = f\"{BASE}/data\"\n",
        "DIR_RESULTS = f\"{BASE}/results\"\n",
        "DIR_FIG_METHOD = f\"{BASE}/figures/methodology\"\n",
        "DIR_FIG_RESULTS = f\"{BASE}/figures/results\"\n",
        "DIR_NOTEBOOK = f\"{BASE}/notebook\"\n",
        "\n",
        "for d in [DIR_DATA, DIR_RESULTS, DIR_FIG_METHOD, DIR_FIG_RESULTS, DIR_NOTEBOOK]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "print(\"âœ… Directories ready. Output path set to current directory.\")\n"
      ],
      "metadata": {
        "id": "F7k_FuATrgnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data (with Auto-Generated Dummy Data)\n",
        "We attempt to load the real MIMIC-III dataset (`cardio_notes.csv`). If the file is not found (e.g., when running this notebook publicly without private data access), the code will **automatically generate a synthetic dataset**.\n",
        "\n",
        "This ensures the notebook is fully executable for demonstration purposes without compromising patient privacy."
      ],
      "metadata": {
        "id": "TD_It-VZPvDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "BASE = \".\"\n",
        "DIR_DATA = f\"{BASE}/data\"\n",
        "DIR_RESULTS = f\"{BASE}/results\"\n",
        "\n",
        "os.makedirs(DIR_DATA, exist_ok=True)\n",
        "os.makedirs(DIR_RESULTS, exist_ok=True)\n",
        "\n",
        "\n",
        "csv_path = f\"{DIR_DATA}/cardio_notes.csv\"\n",
        "\n",
        "def create_dummy_data():\n",
        "    \"\"\"Generates synthetic data for demonstration when real data is missing.\"\"\"\n",
        "    print(\"âš ï¸ [Notice] Real MIMIC-III data not found at:\", csv_path)\n",
        "    print(\"ðŸ”„ Generating SYNTHETIC DUMMY DATA for demonstration...\")\n",
        "\n",
        "    dummy_texts = [\n",
        "        \"Patient presents with severe chest pain and history of CAD.\",\n",
        "        \"Discharge summary: Patient stable, no cardiac issues reported.\",\n",
        "        \"Diagnosed with congestive heart failure (CHF), prescribed lasix.\",\n",
        "        \"Routine checkup, blood pressure normal, no complaints.\",\n",
        "        \"History of myocardial infarction (MI), now complaining of dyspnea.\",\n",
        "        \"Fractured arm from fall, otherwise healthy.\",\n",
        "        \"Patient shows signs of coronary artery disease.\",\n",
        "        \"Normal recovery from surgery, discharged home.\",\n",
        "        \"Hypertension and hyperlipidemia, monitoring required.\",\n",
        "        \"No significant medical history.\"\n",
        "    ] * 10\n",
        "\n",
        "    ids = range(10000, 10000 + len(dummy_texts))\n",
        "\n",
        "    keywords = ['cad', 'heart', 'infarction', 'coronary', 'chf']\n",
        "    labels = [1 if any(k in t.lower() for k in keywords) else 0 for t in dummy_texts]\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        \"subject_id\": ids,\n",
        "        \"hadm_id\": ids,\n",
        "        \"text\": dummy_texts,\n",
        "        \"target\": labels\n",
        "    })\n",
        "\n",
        "if os.path.exists(csv_path):\n",
        "    print(f\"âœ… Found local file: {csv_path}\")\n",
        "    df = pd.read_csv(csv_path)\n",
        "else:\n",
        "    df = create_dummy_data()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"âš ï¸  WARNING: RUNNING IN DEMO MODE WITH DUMMY DATA  âš ï¸\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"1. Real MIMIC-III data was not found, so synthetic data is used.\")\n",
        "    print(\"2. The metrics (Accuracy, AUC) produced here are MEANINGLESS.\")\n",
        "    print(\"3. This run is ONLY to demonstrate that the code executes without errors.\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", list(df.columns))\n",
        "\n",
        "required_cols = [\"subject_id\", \"hadm_id\", \"text\", \"target\"]\n",
        "missing = [c for c in required_cols if c not in df.columns]\n",
        "if missing:\n",
        "    print(f\"Warning: Missing columns {missing}, filling with placeholders.\")\n",
        "    for c in missing:\n",
        "        df[c] = 0\n",
        "\n",
        "vc = df[\"target\"].value_counts(dropna=False).sort_index()\n",
        "print(\"\\nTarget distribution:\\n\", vc)\n",
        "\n",
        "snap_path = f\"{DIR_DATA}/cardio_notes_snapshot.csv\"\n",
        "df.to_csv(snap_path, index=False)\n",
        "print(\"Saved snapshot to:\", snap_path)"
      ],
      "metadata": {
        "id": "adrRnMxJnAQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Preprocessing\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Simple text preprocessing:\n",
        "    - Lowercase\n",
        "    - Remove extra whitespace\n",
        "    - Remove long numeric sequences (anonymization helper)\n",
        "    \"\"\"\n",
        "    t = str(text).lower()\n",
        "    # Remove newlines and extra spaces\n",
        "    t = re.sub(r'\\s+', ' ', t)\n",
        "    # Remove long digit sequences (e.g. phone numbers, IDs > 4 digits)\n",
        "    t = re.sub(r'\\d{4,}', '[NUM]', t)\n",
        "    return t.strip()\n",
        "\n",
        "# Apply cleaning\n",
        "print(\"Running preprocessing...\")\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "print(\"Preprocessing complete. Example:\")\n",
        "print(\"Original:\", df['text'].iloc[0][:50] + \"...\")\n",
        "print(\"Cleaned :\", df['clean_text'].iloc[0][:50] + \"...\")"
      ],
      "metadata": {
        "id": "QlIRZFV2cYdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-test split\n",
        "We split the dataset into training and testing sets (80% / 20%), using stratified sampling to maintain the ratio of positive and negative samples in both sets.\n"
      ],
      "metadata": {
        "id": "iFfEvvRAP85L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Stratified split 80/20\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['clean_text'],\n",
        "    df['target'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['target']\n",
        ")\n",
        "\n",
        "print(f\"Train size: {len(X_train)} | Test size: {len(X_test)}\")\n",
        "\n",
        "# Save splits to CSV (using the directories we set up earlier)\n",
        "train_df = pd.DataFrame({'clean_text': X_train, 'target': y_train})\n",
        "test_df  = pd.DataFrame({'clean_text': X_test,  'target': y_test})\n",
        "\n",
        "train_path = f\"{DIR_DATA}/train.csv\"\n",
        "test_path  = f\"{DIR_DATA}/test.csv\"\n",
        "\n",
        "train_df.to_csv(train_path, index=False)\n",
        "test_df.to_csv(test_path, index=False)\n",
        "\n",
        "print(f\"âœ… Saved train/test sets to:\\n - {train_path}\\n - {test_path}\")\n",
        "\n",
        "# Check distribution\n",
        "print(\"\\nTrain target distribution:\\n\", y_train.value_counts().sort_index())\n",
        "print(\"Test target distribution:\\n\", y_test.value_counts().sort_index())"
      ],
      "metadata": {
        "id": "ZoxSKQYFnDat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, numpy as np, torch\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "try:\n",
        "    torch.manual_seed(SEED)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(SEED)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "except Exception:\n",
        "    pass\n",
        "print(\"Seed fixed:\", SEED)\n"
      ],
      "metadata": {
        "id": "Cvvn7zt7EmeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline: TF-IDF + Logistic Regression\n",
        "We vectorize the text using TF-IDF (term frequencyâ€“inverse document frequency) with unigrams and bigrams, and train a Logistic Regression classifier as the baseline model. This approach is simple, fast, and interpretable.\n"
      ],
      "metadata": {
        "id": "1rjp2FDDP6yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "\n",
        "# 1. Vectorization\n",
        "print(\"Vectorizing text...\")\n",
        "# Limit features to 5000 to keep it manageable\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# 2. Training\n",
        "print(\"Training Logistic Regression...\")\n",
        "clf = LogisticRegression(max_iter=200, random_state=42)\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# 3. Prediction & Evaluation\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "acc_val = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {acc_val:.4f}\")\n",
        "\n",
        "# Classification Report\n",
        "rep = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
        "pd.DataFrame(rep).transpose().to_csv(f\"{DIR_RESULTS}/baseline_results.csv\")\n",
        "\n",
        "# 4. AUC Calculation\n",
        "auc_val = None\n",
        "try:\n",
        "    # LR has predict_proba\n",
        "    probs = clf.predict_proba(X_test_tfidf)[:, 1]\n",
        "    auc_val = roc_auc_score(y_test, probs)\n",
        "    print(f\"AUC: {auc_val:.4f}\")\n",
        "except Exception as e:\n",
        "    print(f\"AUC compute error (possibly single class in dummy data): {e}\")\n",
        "\n",
        "# 5. Save Aggregated Results (Prevent duplicates)\n",
        "row = {\n",
        "    \"model\": \"TFIDF_LR\",\n",
        "    \"accuracy\": float(acc_val),\n",
        "    \"macro_f1\": rep.get(\"macro avg\", {}).get(\"f1-score\", 0),\n",
        "    \"auc\": float(auc_val) if auc_val is not None else None\n",
        "}\n",
        "\n",
        "agg_path = f\"{DIR_RESULTS}/results_all_models.csv\"\n",
        "if os.path.exists(agg_path):\n",
        "    prev = pd.read_csv(agg_path)\n",
        "    # Append and drop duplicates to keep file clean\n",
        "    new_df = pd.concat([prev, pd.DataFrame([row])], ignore_index=True)\n",
        "    new_df.drop_duplicates(subset=[\"model\"], keep=\"last\", inplace=True)\n",
        "    new_df.to_csv(agg_path, index=False)\n",
        "else:\n",
        "    pd.DataFrame([row]).to_csv(agg_path, index=False)\n",
        "\n",
        "print(\"Saved results to:\", agg_path)\n",
        "\n",
        "# 6. Update metrics.json (for easy parsing later)\n",
        "metrics_json_path = f\"{DIR_RESULTS}/metrics.json\"\n",
        "try:\n",
        "    data = json.load(open(metrics_json_path)) if os.path.exists(metrics_json_path) else {}\n",
        "except:\n",
        "    data = {}\n",
        "\n",
        "data[\"baseline_tfidf_logreg_acc\"] = float(acc_val)\n",
        "if auc_val: data[\"baseline_tfidf_logreg_auc\"] = float(auc_val)\n",
        "\n",
        "with open(metrics_json_path, \"w\") as f:\n",
        "    json.dump(data, f, indent=2)\n",
        "print(\"Updated metrics.json\")"
      ],
      "metadata": {
        "id": "LvbKIc-1nFUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SHAP explainability for the baseline\n",
        "We use SHAP (SHapley Additive exPlanations) to identify the most important words influencing the baseline model's predictions. The summary plot shows both the magnitude and direction of each feature's impact.\n"
      ],
      "metadata": {
        "id": "sVkXcI8BQQKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(\"Running SHAP analysis for TF-IDF...\")\n",
        "\n",
        "# 1. Setup SHAP Explainer\n",
        "# Use a background set (summarized via k-means or just sampling)\n",
        "# Since TF-IDF is sparse, we pass the sparse matrix directly to LinearExplainer\n",
        "# Independent masker is good for linear models\n",
        "masker = shap.maskers.Independent(X_train_tfidf, max_samples=100)\n",
        "explainer = shap.LinearExplainer(clf, masker=masker)\n",
        "\n",
        "# 2. Calculate SHAP values for a subset of test data\n",
        "# Cap sample size to 1000 or full test size\n",
        "sample_size = min(1000, X_test_tfidf.shape[0])\n",
        "X_sample = X_test_tfidf[:sample_size]\n",
        "sv = explainer(X_sample)\n",
        "\n",
        "# Get feature names\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# 3. Plot & Save: Bar Plot (Global Importance)\n",
        "plt.figure(figsize=(10, 6))\n",
        "shap.plots.bar(sv, max_display=20, show=False)\n",
        "plt.title(\"SHAP Feature Importance (TF-IDF + LR)\")\n",
        "plt.savefig(f\"{DIR_FIG_RESULTS}/shap_tfidf_bar.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.savefig(f\"{DIR_FIG_RESULTS}/shap_tfidf_bar.pdf\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "# 4. Plot & Save: Summary Plot (Directionality)\n",
        "# Summary plot needs dense matrix for color coding feature values\n",
        "X_sample_dense = X_sample.toarray()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "shap.summary_plot(sv.values, X_sample_dense, feature_names=feature_names, max_display=20, show=False)\n",
        "plt.savefig(f\"{DIR_FIG_RESULTS}/shap_tfidf_summary.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.savefig(f\"{DIR_FIG_RESULTS}/shap_tfidf_summary.pdf\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "print(f\"âœ… SHAP plots saved to: {DIR_FIG_RESULTS}\")"
      ],
      "metadata": {
        "id": "tOFB13R3nH3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ClinicalBERT embeddings\n",
        "We use the pre-trained ClinicalBERT model to encode the discharge summaries into dense semantic vectors. Mean pooling is applied over token embeddings to produce one fixed-size vector (768 dimensions) per note.\n"
      ],
      "metadata": {
        "id": "iCniv5WBQXiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(\"ðŸš€ Loading ClinicalBERT model...\")\n",
        "\n",
        "# 1. Setup Device & Model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"   Device: {device}\")\n",
        "\n",
        "model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    bert = AutoModel.from_pretrained(model_name).to(device)\n",
        "    bert.eval()\n",
        "    print(\"âœ… Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error loading model: {e}\")\n",
        "    # Fallback or exit logic if needed\n",
        "\n",
        "# 2. Define Embedding Function\n",
        "def batch_embed(texts, batch_size=32, max_length=256, pool='mean'):\n",
        "    \"\"\"\n",
        "    Generates embeddings in batches to avoid OOM errors.\n",
        "    pool='mean' -> Average pooling (ignoring padding).\n",
        "    \"\"\"\n",
        "    embs = []\n",
        "    # Ensure texts is a list\n",
        "    text_list = texts.tolist() if hasattr(texts, \"tolist\") else list(texts)\n",
        "\n",
        "    # Progress bar\n",
        "    for i in tqdm(range(0, len(text_list), batch_size), desc=\"Embedding\"):\n",
        "        batch = text_list[i:i+batch_size]\n",
        "\n",
        "        # Tokenize\n",
        "        enc = tokenizer(\n",
        "            batch,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = bert(**enc)\n",
        "\n",
        "            if pool == 'cls':\n",
        "                # Use [CLS] token\n",
        "                v = out.last_hidden_state[:, 0, :]\n",
        "            else:\n",
        "                # Mean pooling with attention mask\n",
        "                mask = enc.attention_mask.unsqueeze(-1)  # [B, L, 1]\n",
        "                # Sum of token embeddings (excluding padding)\n",
        "                summed = (out.last_hidden_state * mask).sum(dim=1)\n",
        "                # Count of valid tokens\n",
        "                counts = mask.sum(dim=1).clamp(min=1)\n",
        "                v = summed / counts\n",
        "\n",
        "        embs.append(v.detach().cpu())\n",
        "\n",
        "    # Concatenate all batches\n",
        "    return torch.vstack(embs).numpy()\n",
        "\n",
        "# 3. Run Embedding\n",
        "print(\"\\nGenerating embeddings for Training set...\")\n",
        "Xtr_emb = batch_embed(X_train, batch_size=32)\n",
        "\n",
        "print(\"Generating embeddings for Test set...\")\n",
        "Xte_emb = batch_embed(X_test, batch_size=32)\n",
        "\n",
        "print(f\"\\nEmbeddings shape: Train {Xtr_emb.shape} | Test {Xte_emb.shape}\")\n",
        "\n",
        "# 4. Save to Disk (as .npy)\n",
        "# Save to the local data directory defined earlier\n",
        "np.save(f\"{DIR_DATA}/Xtr_emb_clinicalbert.npy\", Xtr_emb)\n",
        "np.save(f\"{DIR_DATA}/Xte_emb_clinicalbert.npy\", Xte_emb)\n",
        "\n",
        "# Save a subset for quick SHAP analysis later (optional but helpful)\n",
        "np.save(f\"{DIR_DATA}/Xte_emb_clinicalbert_sample1000.npy\", Xte_emb[:1000])\n",
        "\n",
        "print(f\"âœ… Saved embeddings to {DIR_DATA}/\")\n"
      ],
      "metadata": {
        "id": "Uh6Fx6BpHgGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ClinicalBERT + Logistic Regression\n",
        "We train a Logistic Regression classifier using the ClinicalBERT embeddings as features. This tests whether contextual embeddings improve prediction performance compared to the TF-IDF baseline.\n"
      ],
      "metadata": {
        "id": "x9jvH6SgQpqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "print(\"ðŸš€ Training ClinicalBERT + Logistic Regression...\")\n",
        "\n",
        "# 1. Train Model\n",
        "# Increase max_iter to ensure convergence\n",
        "lr = LogisticRegression(max_iter=1000, n_jobs=-1, random_state=42)\n",
        "lr.fit(Xtr_emb, y_train)\n",
        "\n",
        "# 2. Predict & Evaluate\n",
        "pred = lr.predict(Xte_emb)\n",
        "acc_lr = accuracy_score(y_test, pred)\n",
        "print(f\"Accuracy: {acc_lr:.4f}\")\n",
        "\n",
        "# Save detailed report\n",
        "rep_lr = classification_report(y_test, pred, output_dict=True, zero_division=0)\n",
        "pd.DataFrame(rep_lr).transpose().to_csv(f\"{DIR_RESULTS}/clinicalbert_lr_results.csv\")\n",
        "\n",
        "# 3. Calculate AUC\n",
        "auc_lr = None\n",
        "try:\n",
        "    probs = lr.predict_proba(Xte_emb)[:, 1]\n",
        "    auc_lr = roc_auc_score(y_test, probs)\n",
        "    print(f\"AUC: {auc_lr:.4f}\")\n",
        "except Exception as e:\n",
        "    print(f\"AUC compute error: {e}\")\n",
        "\n",
        "# 4. Save Aggregated Results (Prevent duplicates)\n",
        "row_lr = {\n",
        "    \"model\": \"ClinicalBERT_LR\",\n",
        "    \"accuracy\": float(acc_lr),\n",
        "    \"macro_f1\": rep_lr.get(\"macro avg\", {}).get(\"f1-score\", 0),\n",
        "    \"auc\": float(auc_lr) if auc_lr is not None else None\n",
        "}\n",
        "\n",
        "agg_path = f\"{DIR_RESULTS}/results_all_models.csv\"\n",
        "if os.path.exists(agg_path):\n",
        "    prev = pd.read_csv(agg_path)\n",
        "    new_df = pd.concat([prev, pd.DataFrame([row_lr])], ignore_index=True)\n",
        "    # Drop duplicates to keep file clean\n",
        "    new_df.drop_duplicates(subset=[\"model\"], keep=\"last\", inplace=True)\n",
        "    new_df.to_csv(agg_path, index=False)\n",
        "else:\n",
        "    pd.DataFrame([row_lr]).to_csv(agg_path, index=False)\n",
        "\n",
        "# 5. Update metrics.json\n",
        "metrics_json_path = f\"{DIR_RESULTS}/metrics.json\"\n",
        "try:\n",
        "    data = json.load(open(metrics_json_path)) if os.path.exists(metrics_json_path) else {}\n",
        "except:\n",
        "    data = {}\n",
        "\n",
        "data[\"clinicalbert_lr_acc\"] = float(acc_lr)\n",
        "if auc_lr: data[\"clinicalbert_lr_auc\"] = float(auc_lr)\n",
        "\n",
        "with open(metrics_json_path, \"w\") as f:\n",
        "    json.dump(data, f, indent=2)\n",
        "\n",
        "print(\"âœ… Results saved.\")"
      ],
      "metadata": {
        "id": "SGByBrIeHSs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Running SHAP analysis for ClinicalBERT + LR...\")\n",
        "\n",
        "# 1. Setup Explainer\n",
        "# LinearExplainer works well with LR on embeddings\n",
        "# We use Xtr_emb as background distribution\n",
        "explainer_lr = shap.LinearExplainer(lr, Xtr_emb)\n",
        "\n",
        "# 2. Calculate SHAP values\n",
        "# Sample at most 1000 points\n",
        "sample_size = min(1000, Xte_emb.shape[0])\n",
        "X_sample = Xte_emb[:sample_size]\n",
        "sv_lr = explainer_lr(X_sample)\n",
        "\n",
        "# 3. Plot & Save: Bar Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "# max_display=20 shows top 20 embedding dimensions\n",
        "shap.plots.bar(sv_lr, max_display=20, show=False)\n",
        "plt.title(\"SHAP Feature Importance (ClinicalBERT + LR)\")\n",
        "plt.savefig(f\"{DIR_FIG_RESULTS}/shap_clinicalbert_lr_bar.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.savefig(f\"{DIR_FIG_RESULTS}/shap_clinicalbert_lr_bar.pdf\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "print(f\"âœ… SHAP plots saved to: {DIR_FIG_RESULTS}/shap_clinicalbert_lr_bar.png\")"
      ],
      "metadata": {
        "id": "IRoJlid0Hk8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ClinicalBERT + XGBoost\n",
        "We train an XGBoost classifier on ClinicalBERT embeddings. XGBoost can model nonlinear feature interactions, which may capture more complex patterns in the semantic embeddings.\n"
      ],
      "metadata": {
        "id": "HXfxjnWlQrq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "print(\"ðŸš€ Training ClinicalBERT + XGBoost...\")\n",
        "\n",
        "# 1. Train Model\n",
        "# Added random_state for reproducibility\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    reg_lambda=1.0,\n",
        "    tree_method=\"hist\",  # Efficient for larger data\n",
        "    eval_metric=\"logloss\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "xgb_clf.fit(Xtr_emb, y_train)\n",
        "\n",
        "# 2. Predict & Evaluate\n",
        "pred_x = xgb_clf.predict(Xte_emb)\n",
        "# Get probability for class 1\n",
        "proba_x = xgb_clf.predict_proba(Xte_emb)[:, 1]\n",
        "\n",
        "acc_xgb = accuracy_score(y_test, pred_x)\n",
        "print(f\"ClinicalBERT+XGB Accuracy: {acc_xgb:.4f}\")\n",
        "\n",
        "# Save detailed report\n",
        "rep_xgb = classification_report(y_test, pred_x, output_dict=True, zero_division=0)\n",
        "pd.DataFrame(rep_xgb).transpose().to_csv(f\"{DIR_RESULTS}/clinicalbert_xgb_results.csv\")\n",
        "\n",
        "# 3. Calculate AUC\n",
        "auc_xgb = roc_auc_score(y_test, proba_x)\n",
        "print(f\"AUC: {auc_xgb:.4f}\")\n",
        "\n",
        "# 4. Save Aggregated Results (Prevent duplicates)\n",
        "row_xgb = {\n",
        "    \"model\": \"ClinicalBERT_XGB\",\n",
        "    \"accuracy\": float(acc_xgb),\n",
        "    \"macro_f1\": rep_xgb.get(\"macro avg\", {}).get(\"f1-score\", 0),\n",
        "    \"auc\": float(auc_xgb)\n",
        "}\n",
        "\n",
        "agg_path = f\"{DIR_RESULTS}/results_all_models.csv\"\n",
        "if os.path.exists(agg_path):\n",
        "    prev = pd.read_csv(agg_path)\n",
        "    new_df = pd.concat([prev, pd.DataFrame([row_xgb])], ignore_index=True)\n",
        "    # Drop duplicates to keep file clean\n",
        "    new_df.drop_duplicates(subset=[\"model\"], keep=\"last\", inplace=True)\n",
        "    new_df.to_csv(agg_path, index=False)\n",
        "else:\n",
        "    pd.DataFrame([row_xgb]).to_csv(agg_path, index=False)\n",
        "\n",
        "# 5. Update metrics.json\n",
        "metrics_json_path = f\"{DIR_RESULTS}/metrics.json\"\n",
        "try:\n",
        "    data = json.load(open(metrics_json_path)) if os.path.exists(metrics_json_path) else {}\n",
        "except:\n",
        "    data = {}\n",
        "\n",
        "data[\"clinicalbert_xgb_acc\"] = float(acc_xgb)\n",
        "data[\"clinicalbert_xgb_auc\"] = float(auc_xgb)\n",
        "\n",
        "with open(metrics_json_path, \"w\") as f:\n",
        "    json.dump(data, f, indent=2)\n",
        "\n",
        "print(\"âœ… Results saved.\")"
      ],
      "metadata": {
        "id": "2VguNgQpL3Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Running SHAP analysis for XGBoost...\")\n",
        "\n",
        "# 1. Setup Explainer\n",
        "# TreeExplainer is optimized for XGBoost\n",
        "explainer_xgb = shap.TreeExplainer(xgb_clf)\n",
        "\n",
        "# 2. Calculate SHAP values\n",
        "# Sample at most 1000 points\n",
        "sample_size = min(1000, Xte_emb.shape[0])\n",
        "X_sample = Xte_emb[:sample_size]\n",
        "\n",
        "# Calculate shap values\n",
        "sv_xgb = explainer_xgb.shap_values(X_sample)\n",
        "\n",
        "# 3. Plot & Save: Summary Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "shap.summary_plot(sv_xgb, X_sample, max_display=20, show=False)\n",
        "plt.title(\"SHAP Feature Importance (ClinicalBERT + XGBoost)\")\n",
        "plt.savefig(f\"{DIR_FIG_RESULTS}/shap_clinicalbert_xgb_summary.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.savefig(f\"{DIR_FIG_RESULTS}/shap_clinicalbert_xgb_summary.pdf\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "print(f\"âœ… SHAP plots saved to: {DIR_FIG_RESULTS}/shap_clinicalbert_xgb_summary.png\")"
      ],
      "metadata": {
        "id": "4Ls8UPYGHo-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## roc_comparison"
      ],
      "metadata": {
        "id": "0kmPFI5T_1OM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import pandas as pd\n",
        "\n",
        "print(\"ðŸŽ¨ Generating ROC Curve and LaTeX Table...\")\n",
        "\n",
        "# === Part 1: ROC Curve Plot ===\n",
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "# Plot TF-IDF (clf)\n",
        "# Note: Check if model exists, handles dummy data scenarios\n",
        "if 'clf' in globals():\n",
        "    probs = clf.predict_proba(X_test_tfidf)[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_test, probs)\n",
        "    plt.plot(fpr, tpr, label=f'TF-IDF + LR (AUC={auc(fpr, tpr):.3f})')\n",
        "\n",
        "# Plot ClinicalBERT + LR (lr)\n",
        "if 'lr' in globals():\n",
        "    probs = lr.predict_proba(Xte_emb)[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_test, probs)\n",
        "    plt.plot(fpr, tpr, label=f'ClinicalBERT + LR (AUC={auc(fpr, tpr):.3f})')\n",
        "\n",
        "# Plot ClinicalBERT + XGB (xgb_clf)\n",
        "if 'xgb_clf' in globals():\n",
        "    probs = xgb_clf.predict_proba(Xte_emb)[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_test, probs)\n",
        "    plt.plot(fpr, tpr, label=f'ClinicalBERT + XGB (AUC={auc(fpr, tpr):.3f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Comparison')\n",
        "plt.legend(loc='lower right')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save\n",
        "plt.savefig(f\"{DIR_FIG_RESULTS}/roc_comparison.png\", dpi=300)\n",
        "plt.savefig(f\"{DIR_FIG_RESULTS}/roc_comparison.pdf\", dpi=300)\n",
        "plt.show()\n",
        "plt.close()\n",
        "print(f\"âœ… ROC Curve saved to {DIR_FIG_RESULTS}\")\n",
        "\n",
        "\n",
        "# === Part 2: Generate LaTeX Table ===\n",
        "# Read the aggregated results\n",
        "if os.path.exists(agg_path):\n",
        "    tbl = pd.read_csv(agg_path)\n",
        "\n",
        "    # Format numbers\n",
        "    tbl['accuracy'] = tbl['accuracy'].apply(lambda x: f\"{x:.4f}\")\n",
        "    tbl['macro_f1'] = tbl['macro_f1'].apply(lambda x: f\"{x:.4f}\" if pd.notnull(x) else \"-\")\n",
        "    tbl['auc'] = tbl['auc'].apply(lambda x: f\"{x:.4f}\" if pd.notnull(x) else \"-\")\n",
        "\n",
        "    # Map names to pretty strings\n",
        "    name_map = {\n",
        "        \"TFIDF_LR\": \"TF-IDF + LR\",\n",
        "        \"ClinicalBERT_LR\": \"ClinicalBERT + LR\",\n",
        "        \"ClinicalBERT_XGB\": \"ClinicalBERT + XGB\"\n",
        "    }\n",
        "\n",
        "    print(\"\\n--- Copy this LaTeX code into your Overleaf ---\")\n",
        "    print(r\"\\begin{table}[htbp]\")\n",
        "    print(r\"\\caption{Model performance comparison.}\")\n",
        "    print(r\"\\label{tab:results}\")\n",
        "    print(r\"\\centering\")\n",
        "    print(r\"\\begin{tabular}{lccc}\")\n",
        "    print(r\"\\toprule\")\n",
        "    print(r\"Model & Accuracy & Macro F1 & AUC \\\\\")\n",
        "    print(r\"\\midrule\")\n",
        "\n",
        "    for _, r in tbl.iterrows():\n",
        "        model_name = name_map.get(r['model'], r['model'])\n",
        "        print(f\"{model_name} & {r['accuracy']} & {r['macro_f1']} & {r['auc']} \\\\\\\\\")\n",
        "\n",
        "    print(r\"\\bottomrule\")\n",
        "    print(r\"\\end{tabular}\")\n",
        "    print(r\"\\end{table}\")\n",
        "    print(\"----------------------------------------------\")"
      ],
      "metadata": {
        "id": "H1ADAj82CHIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate Diagrams (Figures 1 & 2)\n",
        "# Install Graphviz (System dependency)\n",
        "!apt-get -y install graphviz > /dev/null 2>&1\n",
        "!pip install graphviz\n",
        "\n",
        "from graphviz import Digraph\n",
        "import os\n",
        "\n",
        "print(\"ðŸŽ¨ Generating Project Diagrams...\")\n",
        "\n",
        "# Helper function\n",
        "def render_both(g, save_dir, filename):\n",
        "    g.format = \"png\"\n",
        "    g.render(filename=os.path.join(save_dir, filename), cleanup=True)\n",
        "    g.format = \"pdf\"\n",
        "    g.render(filename=os.path.join(save_dir, filename), cleanup=True)\n",
        "    print(f\"   Saved {filename} (.png & .pdf)\")\n",
        "\n",
        "# --- Figure 1: Data Extraction ---\n",
        "g1 = Digraph('data_extraction')\n",
        "g1.attr(rankdir='LR', fontsize='12', fontname='Helvetica')\n",
        "\n",
        "g1.node('D', 'MIMIC-III\\n(ICD-9 410-414, 428)', shape='database', style='filled', fillcolor='#E0F7FA')\n",
        "g1.node('P', 'Preprocessing\\n(Filter, Clean, Split)', shape='box', style='filled', fillcolor='#FFF3E0')\n",
        "g1.node('csv', 'Labeled Dataset\\n(Train/Test CSV)', shape='note', style='filled', fillcolor='#F1F8E9')\n",
        "\n",
        "g1.edge('D', 'P', label=' Extract')\n",
        "g1.edge('P', 'csv', label=' Save')\n",
        "\n",
        "render_both(g1, DIR_FIG_METHOD, 'fig_data_extraction')\n",
        "\n",
        "\n",
        "# --- Figure 2: Model Pipeline ---\n",
        "g2 = Digraph('model_pipeline')\n",
        "g2.attr(rankdir='LR', fontsize='12', fontname='Helvetica')\n",
        "\n",
        "g2.node('In', 'Clinical Text', shape='note')\n",
        "g2.node('TF', 'TF-IDF\\n(n-grams)', shape='box', style='rounded')\n",
        "g2.node('BERT', 'ClinicalBERT\\n(Embeddings)', shape='box', style='rounded')\n",
        "\n",
        "g2.node('LR1', 'Logistic Regression', shape='ellipse', style='filled', fillcolor='#E1BEE7')\n",
        "g2.node('LR2', 'Logistic Regression', shape='ellipse', style='filled', fillcolor='#E1BEE7')\n",
        "g2.node('XGB', 'XGBoost', shape='ellipse', style='filled', fillcolor='#FFCCBC')\n",
        "\n",
        "g2.edge('In', 'TF')\n",
        "g2.edge('In', 'BERT')\n",
        "\n",
        "g2.edge('TF', 'LR1')\n",
        "g2.edge('BERT', 'LR2')\n",
        "g2.edge('BERT', 'XGB')\n",
        "\n",
        "render_both(g2, DIR_FIG_METHOD, 'fig_model_pipeline')\n",
        "print(\"âœ… Diagrams generated in\", DIR_FIG_METHOD)"
      ],
      "metadata": {
        "id": "OOZ-5OpgCNG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Bundle & Verify\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "print(\"ðŸ“¦ Verifying Outputs...\")\n",
        "print(f\"   Data: {len(glob.glob(f'{DIR_DATA}/*'))} files\")\n",
        "print(f\"   Results: {len(glob.glob(f'{DIR_RESULTS}/*'))} files\")\n",
        "print(f\"   Figures: {len(glob.glob(f'{DIR_FIG_RESULTS}/*'))} files\")\n",
        "\n",
        "# Create a zip bundle for easy download\n",
        "shutil.make_archive('project_submission', 'zip', BASE)\n",
        "\n",
        "print(\"\\nðŸŽ‰ ALL DONE! You can now download 'project_submission.zip' from the file browser on the left.\")\n",
        "print(\"   This zip contains your Code, Data (dummy), Results, and Figures.\")"
      ],
      "metadata": {
        "id": "oOKHbbvfDIJj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}